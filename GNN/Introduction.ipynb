{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "- adjacency matrix\n",
        "- sparse matrices in PyTorch\n",
        "- message passing example"
      ],
      "metadata": {
        "id": "WkLjxrGf8A3c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tiy3JPKP77bo"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/6n-graph2.svg/800px-6n-graph2.svg.png\" width=\"200\" height=\"200\"/>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "7Fa7WfFs8Fnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NxN adjacency matrix\n",
        "adj = torch.tensor([\n",
        "    [2, 1, 0, 0, 1, 0],\n",
        "    [1, 0, 1, 0, 1, 0],\n",
        "    [0, 1, 0, 1, 0, 0],\n",
        "    [0, 0, 1, 0, 1, 1],\n",
        "    [1, 1, 0, 1, 0, 0],\n",
        "    [0, 0, 0, 1, 0, 0],\n",
        "], dtype=torch.float)"
      ],
      "metadata": {
        "id": "iMIaJ6ZC8EB0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NxF node feature matrix: each node has 3 associated features\n",
        "fea = torch.tensor([\n",
        "    [0.10, 0.20, 0.10],\n",
        "    [0.50, 0.0, 0.25],\n",
        "    [0.50, 0.0, 0.25],\n",
        "    [0.25, 0.25, 0.50],\n",
        "    [0.30, 0.45, 0.40],\n",
        "    [0.90, 0.60, 0.30],\n",
        "])"
      ],
      "metadata": {
        "id": "Vg188oOF8bRv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# message passing is a matrix multiplication plus a matrix addition:\n",
        "# new features computed from the node's previous features and its neighbors' previous features\n",
        "fea + torch.mm(adj, fea)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kW5bkXQ8hDH",
        "outputId": "a60eeccc-0dc9-4142-b8fb-26d150ae5a19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1000, 1.0500, 0.9500],\n",
              "        [1.4000, 0.6500, 1.0000],\n",
              "        [1.2500, 0.2500, 1.0000],\n",
              "        [1.9500, 1.3000, 1.4500],\n",
              "        [1.1500, 0.9000, 1.2500],\n",
              "        [1.1500, 0.8500, 0.8000]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# turn to sparse matrix format\n",
        "# real-world graphs are very sparse: the number of their edges is a small fraction of the possible NxN edges\n",
        "# so we can sparse a large amount of computer memory storing the adjacency matrix this way\n",
        "adj.to_sparse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45ELrqYg8ilv",
        "outputId": "b47364cb-975b-41c1-c7ac-f6699e6cbd06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(indices=tensor([[0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5],\n",
              "                       [0, 1, 4, 0, 2, 4, 1, 3, 2, 4, 5, 0, 1, 3, 3]]),\n",
              "       values=tensor([2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1.]),\n",
              "       size=(6, 6), nnz=15, layout=torch.sparse_coo)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch supports sparse-dense matrix multiplication\n",
        "# we can see the same result as before\n",
        "fea + torch.sparse.mm(adj.to_sparse(), fea)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPlmGEYV8moA",
        "outputId": "871529e4-1a28-41eb-a79f-18a2ae5d15be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1000, 1.0500, 0.9500],\n",
              "        [1.4000, 0.6500, 1.0000],\n",
              "        [1.2500, 0.2500, 1.0000],\n",
              "        [1.9500, 1.3000, 1.4500],\n",
              "        [1.1500, 0.9000, 1.2500],\n",
              "        [1.1500, 0.8500, 0.8000]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# networkx is a python package to create, manipulate and visualize graphs\n",
        "import networkx as nx\n",
        "\n",
        "N = 20000\n",
        "p = 0.02\n",
        "\n",
        "# let's generate the sparse adjacency matrix of a larger graph (10000 nodes)\n",
        "adj = nx.to_scipy_sparse_array(\n",
        "    nx.fast_gnp_random_graph(N, p, seed=42), # generates an Erdős-Rényi random graph\n",
        "    format='coo',\n",
        ")\n",
        "\n",
        "# we convert it to pytorch sparse matrix\n",
        "adj = torch.sparse_coo_tensor(\n",
        "    torch.tensor([adj.row, adj.col], dtype=torch.long),\n",
        "    torch.tensor(adj.data, dtype=torch.float),\n",
        "    size=torch.Size(adj.shape)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugrtZHNb8oxA",
        "outputId": "4aec1526-75b7-4a71-a8c9-13c939423857"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b2bbf11fb98b>:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  torch.tensor([adj.row, adj.col], dtype=torch.long),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "fea = torch.rand((N, 3))\n",
        "\n",
        "adj_cuda = adj.cuda()\n",
        "fea_cuda = fea.cuda()\n",
        "\n",
        "adj_dense = adj.to_dense()\n",
        "adj_cuda_dense = adj.cuda().to_dense()\n",
        "\n",
        "start = time.time()\n",
        "torch.mm(adj_dense, fea)\n",
        "stop = time.time()\n",
        "print(f\"dense-dense multiplication: {stop - start}\")\n",
        "\n",
        "start = time.time()\n",
        "torch.mm(adj_cuda_dense, fea_cuda)\n",
        "stop = time.time()\n",
        "print(f\"dense-dense multiplication on gpu: {stop - start}\")\n",
        "\n",
        "start = time.time()\n",
        "torch.sparse.mm(adj, fea)\n",
        "stop = time.time()\n",
        "print(f\"sparse-dense multiplication: {stop - start}\")\n",
        "\n",
        "start = time.time()\n",
        "torch.mm(adj_cuda, fea_cuda)\n",
        "stop = time.time()\n",
        "print(f\"sparse-dense multiplication on gpu: {stop - start}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiZO9U9U8rex",
        "outputId": "04341e1a-24f8-4fda-bb84-5f4e572cc665"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dense-dense multiplication: 0.2949855327606201\n",
            "dense-dense multiplication on gpu: 0.018737077713012695\n",
            "sparse-dense multiplication: 0.1868126392364502\n",
            "sparse-dense multiplication on gpu: 0.0635378360748291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conclusion: dense-dense matrix multiplication not only consumes high amount of memory,\n",
        "# it is also considerably slower if most entries of the matrix are zero"
      ],
      "metadata": {
        "id": "ou0k_0To8tEx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# beyond node features, edge features are also common but we won't deal with that"
      ],
      "metadata": {
        "id": "wpUR2xBP8uQ0"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}